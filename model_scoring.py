# -*- coding: utf-8 -*-
"""real-estate-ph-opportunity-score.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Tg1pp2pbtC3V3i7PqDRk-c__CqIiYfje

### Authentication
"""
# def get_data_and_weights():

import pandas as pd
import numpy as np
from datetime import date, timedelta, datetime
import plotly.express as px
from google.cloud import bigquery
from google.oauth2 import service_account

key_path = '/Users/fuente/Documents/real_estate_ph_scoring/google_bq_service_account/real-estate-ph-391212-b99a0e22a14a.json'

credentials = service_account.Credentials.from_service_account_file(
        key_path, scopes=['https://www.googleapis.com/auth/cloud-platform'],
    )

from IPython.display import display, HTML

display(HTML("<style>.container { width:100% !important; }</style>"))

client = bigquery.Client(
        credentials=credentials,
        project='real-estate-ph-391212')


"""### BQ data pull"""

income = f"""

    select * from `real-estate-ph-391212.production.avg_income`

    """

population = f"""

    select * from `real-estate-ph-391212.production.avg_population`

    """

emp_rate = f"""

    select * from `real-estate-ph-391212.production.employment_rate`

    """

gva = f"""

    select * from `real-estate-ph-391212.production.gross_value_added`

    """


res_units_built = f"""

    select * from `real-estate-ph-391212.production.residential_units_built`

    """


res_units_sold = f"""

    select * from `real-estate-ph-391212.production.residential_units_sold`

    """

jobee = f"""

select * from `real-estate-ph-391212.production.jollibee_branches`

"""

city_coord = f"""

select * from `real-estate-ph-391212.production.city_coordinates`

"""

df_inc = client.query(income).to_dataframe()
df_pop = client.query(population).to_dataframe()
df_emp = client.query(emp_rate).to_dataframe()
df_gva = client.query(gva).to_dataframe()
df_rsb = client.query(res_units_built).to_dataframe()
df_rss = client.query(res_units_sold).to_dataframe()
df_jbe = client.query(jobee).to_dataframe()
df_map = client.query(city_coord).to_dataframe()

"""### Data processing

    #### Avg. income
    """

df_inc.isna().value_counts()

df_inc[df_inc.isnull().any(axis=1)]

df_inc[df_inc['region_id']=='rxi-001']

df_inc[['avg_income_2015','avg_income_2018','avg_income_2021']] = df_inc[['avg_income_2015','avg_income_2018','avg_income_2021']].astype(float)

type(df_inc.at[25, 'avg_income_2015'])

    # Let's fill the null values with the average of the whole region

    # Calculate the average income for region_id 'rxi-001'
avg_inc = df_inc[df_inc['region_id'] == 'rxi-001']['avg_income_2015'].mean()

    # Fill missing values with the average income for davao occidental davao-oc001'
df_inc['avg_income_2015'].fillna(avg_inc, inplace=True)

df_inc[df_inc['region_id']=='rxi-001']

"""#### Population"""

df_pop.isna().value_counts()

df_pop.dropna(inplace=True)

df_pop.isna().value_counts()

"""#### Employment rate"""

df_emp.isna().value_counts()

"""#### GVA"""

df_gva.isna().value_counts()

"""#### Residential units built"""

df_rsb.isna().value_counts()

df_rsb.dropna(inplace=True)

"""#### Residential units sold"""

df_rss.isna().value_counts()

df_rss.dropna(inplace=True)

"""   #### Jollibee branches """
df_jbe.dropna(inplace=True)
df_jbe['no_of_branches'] = df_jbe['no_of_branches'].str.strip()
df_jbe['no_of_branches'] = df_jbe['no_of_branches'].replace('-',0)

"""   #### City coordinates """

df_map.dropna(inplace=True)


"""### Calculating CAGR

    #### Avg. income
    """

df_inc['gr_2015_2018'] = df_inc['avg_income_2018'] / df_inc['avg_income_2015']
df_inc['gr_2018_2021'] = df_inc['avg_income_2021'] / df_inc['avg_income_2018']
df_inc['income_cagr'] = (df_inc['gr_2015_2018'] * df_inc['gr_2018_2021'])**(1/3)-1

"""#### Population growth"""

df_pop['gr_2000_2005'] = df_pop['avg_population_2005'] / df_pop['avg_population_2000']
df_pop['gr_2005_2015'] = df_pop['avg_population_2015'] / df_pop['avg_population_2005']
df_pop['gr_2015_2020'] = df_pop['avg_population_2020'] / df_pop['avg_population_2015']
df_pop['pop_cagr'] = (df_pop['gr_2000_2005'] * df_pop['gr_2005_2015'] * df_pop['gr_2015_2020'])**(1/4)-1

"""#### Emp rate growth"""

df_emp['gr_2018_2019'] = df_emp['employment_rate_2019'] / df_emp['employment_rate_2018']
df_emp['gr_2019_2020'] = df_emp['employment_rate_2020'] / df_emp['employment_rate_2019']

df_emp['emp_cagr'] = (df_emp['gr_2018_2019'] * df_emp['gr_2019_2020'])**(1/3)-1

"""*For employment rate, we have a negative CAGR in 2020 maybe due to COVID so we're going to user emp_rate for 2019 instead*

    #### GVA
    """

df_gva['gr_2019_2020'] = df_gva['gva_2020'] / df_gva['gva_2019']
df_gva['gr_2020_2021'] = df_gva['gva_2021'] / df_gva['gva_2020']
df_gva['gr_2021_2022'] = df_gva['gva_2022'] / df_gva['gva_2021']
df_gva['gva_cagr'] = (df_gva['gr_2019_2020'] * df_gva['gr_2020_2021'] * df_gva['gr_2021_2022'])**(1/4)-1

"""### Calculating value per unit sold / built"""


df_value = df_gva[['region','region_id','gva_2020','gva_cagr']]

df_value = pd.merge(df_value, df_rsb[['region_id','res_units_built_2020']], on='region_id',how='left')

df_value = pd.merge(df_value, df_rss[['region_id','res_units_sold_2020']], on='region_id',how='left')

df_value['gv_per_unit_built'] = df_value['gva_2020'] / df_value['res_units_built_2020']
df_value['gv_per_unit_sold'] = df_value['gva_2020'] / df_value['res_units_sold_2020']

df_value = df_value[['region_id','gva_2020','gva_cagr','gv_per_unit_built','gv_per_unit_sold']]

"""### Merge datasets into a final df for socring logic"""

df1 = df_pop[['region','region_id','province','provincial_id','city_municipality','city_municipality_id','pop_cagr']]

df2 = pd.merge(df1,df_inc[['region_id','provincial_id','avg_income_2021','income_cagr']], on=(['region_id','provincial_id']), how='left')

df3 = pd.merge(df2,df_emp[['region_id','provincial_id','employment_rate_2019']], on=(['region_id','provincial_id']), how='left')

df4 = pd.merge(df3,df_value, on=(['region_id']), how='left')

df_jbe_final = df_jbe[['city_municipality_id','no_of_branches']]

df5 = pd.merge(df4, df_jbe_final, on=(['city_municipality_id']), how='left')

"""### EDA"""

summary = df5.describe()
summary.transpose()

df4[df5.isnull().any(axis=1)]

"""#### Missing employment rate values"""

df5[df5.isna().any(axis=1)]

"""*It looks like we have missing employment rate for provincial_id = oriental001*"""

df5[df5['region_id']=='mr-001']

    # Let's fill the null values with the average of the whole region

    # Calculate the average employment rate for region_id 'mr-001'
avg_emp_rate = df5[df5['region_id'] == 'mr-001']['employment_rate_2019'].mean()

    # Fill missing values with the average employment rate for region_id 'mr-001'
df5['employment_rate_2019'].fillna(avg_emp_rate, inplace=True)

df5[df5['region_id']=='mr-001']

type(df5.at[61, 'employment_rate_2019'])

summary = df5.describe()
summary.transpose()

"""### Opportunity scoring through MCDA"""

df_scale = df5.copy()

df_scale.rename(columns={'no_of_branches': 'jollibee_branches'}, inplace=True)

df_map_final = df_map[['city_municipality_id','lat','long']]

from sklearn.preprocessing import StandardScaler

    # Initialize a scaler
scaler = StandardScaler()

    # List of numerical columns to standardize
numerical_columns = ['pop_cagr', 'avg_income_2021', 'income_cagr', 'employment_rate_2019',
                        'gva_2020', 'gva_cagr', 'gv_per_unit_built', 'gv_per_unit_sold','jollibee_branches']

    # Standardize the numerical columns

def calculate_scores(df_scale, df5, weights):
    # Standardize the numerical columns
        df_scale[numerical_columns] = scaler.fit_transform(df_scale[numerical_columns])

    # Create a new column 'opportunity_score' by combining the weighted features
        df_scale['opportunity_score'] = df_scale[numerical_columns].mul([weights[col] for col in numerical_columns], axis=1).sum(axis=1)
        df_scale_final = df_scale[['region_id','provincial_id','city_municipality_id','opportunity_score']]

    # Merge df_scale_final with df4
        df_final = pd.merge(df5, df_scale_final, on=(['region_id','provincial_id','city_municipality_id']), how='left')

        region_mapping = {
        'cordillera administrative region (car)': 'CAR',
        'bangsamoro autonomous region in muslim mindanao (barmm)': 'BARMM',
        'region ix (zamboanga peninsula)': 'region ix (zamboanga)',
        'national capital region (ncr)': 'NCR'
        }

        df_final['region'] = df_final['region'].replace(region_mapping)
        df_final = pd.merge(df_final,df_map_final, on=(['city_municipality_id']), how='left')

        return df_final

def get_data_and_weights():
        # Initialize the weights
    weights = {
        'pop_cagr': 0.1,
        'avg_income_2021': 0.2,
        'income_cagr': 0.2,
        'employment_rate_2019': 0.1,
        'gva_2020': 0.05,
        'gva_cagr': 0.05,
        'gv_per_unit_built': 0.1,
        'gv_per_unit_sold': 0.1,
        'jollibee_branches':0.1
    }
    df_final = calculate_scores(df_scale, df4, weights)
    return df_final, weights, df_scale, df4